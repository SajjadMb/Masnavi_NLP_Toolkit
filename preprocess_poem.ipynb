{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf72da55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux 67355a28c126 5.10.60.1-microsoft-standard-WSL2 #1 SMP Wed Aug 25 23:20:18 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux\r\n"
     ]
    }
   ],
   "source": [
    "# ! pip install hazm\n",
    "# ! pip install gensim\n",
    "# ! pip -q install clean-text[gpl]\n",
    "# ! pip3 install transformers\n",
    "! uname -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f064f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from __future__ import unicode_literals\n",
    "import hazm\n",
    "import nltk\n",
    "import codecs\n",
    "import tqdm\n",
    "import gensim\n",
    "from cleantext import clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea38f39",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9573bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('masnavi.txt', 'r', encoding=\"utf8\") as infile:\n",
    "    masnavi_file = infile.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29e86bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [x.strip() for x in codecs.open('stopwords.txt','r','utf-8').readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2196add0",
   "metadata": {},
   "outputs": [],
   "source": [
    "persian_punctuation = ['،','؟',':','\\*','«',\"»\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e90b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = hazm.Normalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffc0049",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = hazm.Lemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3f1427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Masnavi\n",
    "masnavi = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e28e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, tokenize = False):\n",
    "    text = normalizer.normalize(text)\n",
    "    text = lemmatizer.lemmatize(text)\n",
    "    text = re.sub(r\"|\".join(persian_punctuation), \" \", text)\n",
    "    regex = r\"\\b(?:\" + \"|\".join(map(re.escape, stopwords)) + r\")\\b\"\n",
    "    text = re.sub(regex, \" \", text)\n",
    "    text = re.sub(u\"\\u200c\" , \"\", text)\n",
    "    text = re.sub(r'\\s+', \" \", text)\n",
    "    text = text.strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98d200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_couplet(text):\n",
    "    result = re.search(\"(\\d{1,3})\\.(\\d{1,3})\", text)\n",
    "    # check if line contains a couplet\n",
    "    if result:\n",
    "        pno, cno = result.groups()\n",
    "        # delete Daftar and Poem number\n",
    "        couplet = re.sub(\"(\\d{1,3})\\.(\\d{1,3})\", \"\", text)\n",
    "        # extract mesra\n",
    "        hemistich = couplet.split(\"\\t\")[1:3]\n",
    "        # clean mesra\n",
    "        cleaned_hemistich = [clean_text(h) for h in hemistich]\n",
    "        return pno, cno, \"\\t\".join(hemistich), \" \".join(cleaned_hemistich), cleaned_hemistich[0], cleaned_hemistich[1]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60abbba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "daftar = 0\n",
    "for couplet in masnavi_file:\n",
    "    if re.search(\"^(?:دفتر).*.(?:مثنوی)$\", couplet):\n",
    "        daftar += 1\n",
    "        if daftar == 7:\n",
    "            break\n",
    "        print(f\"Processing Daftar {daftar}\")\n",
    "    else:\n",
    "        process_result = process_couplet(couplet)\n",
    "        if process_result:\n",
    "            pno = process_result[0]\n",
    "            cno = process_result[1]\n",
    "            c = process_result[2]\n",
    "            cc = process_result[3]\n",
    "            h1 = process_result[4]\n",
    "            h2 = process_result[5]\n",
    "            masnavi.append((daftar, pno, cno, c, cc, h1, h2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1da460",
   "metadata": {},
   "outputs": [],
   "source": [
    "masnavi_df = pd.DataFrame(masnavi, columns=['Daftar', 'Poem', 'CNo', 'Couplet', 'CCouplet', 'Hemistich1', 'Hemistich2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51711b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "masnavi_df.Hemistich2[200:250]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe681f2",
   "metadata": {},
   "source": [
    "### Process dataframe data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b04f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "masnavi_df['Daftar'] = masnavi_df['Daftar'].apply(pd.to_numeric)\n",
    "masnavi_df['Poem'] = masnavi_df['Poem'].apply(pd.to_numeric)\n",
    "masnavi_df['CNo'] = masnavi_df['CNo'].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad060c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "masnavi_df[masnavi_df['Daftar']==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336b162f",
   "metadata": {},
   "source": [
    "### Create Tokenized columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d84e7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "masnavi_df['Couplet_tokenized'] = masnavi_df['CCouplet'].apply(lambda x:hazm.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bff72df",
   "metadata": {},
   "outputs": [],
   "source": [
    "masnavi_df['Hemistich1_tokenized'] =  masnavi_df['Hemistich1'].apply(lambda x:hazm.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9cc5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "masnavi_df['Hemistich2_tokenized'] =  masnavi_df['Hemistich2'].apply(lambda x:hazm.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7d3457",
   "metadata": {},
   "outputs": [],
   "source": [
    "masnavi_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ca3b7c",
   "metadata": {},
   "source": [
    "### Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92107be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae9083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = list(chain.from_iterable(masnavi_df.Couplet_tokenized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d36f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_frequencies = nltk.FreqDist(all_words).most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af213f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "words_frequencies[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519f411a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('%-16s' % 'Number of words', '%-16s' % len(all_words))\n",
    "print ('%-16s' % 'Number of unique words', '%-16s' % len(set(all_words)))\n",
    "avg=np.sum([len(word) for word in all_words])/len(all_words)\n",
    "print ('%-16s' % 'Average word length', '%-16s' % avg)\n",
    "print ('%-16s' % 'Longest word', '%-16s' % all_words[np.argmax([len(word) for word in all_words])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a665ad5",
   "metadata": {},
   "source": [
    "### TF/IDF Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55f770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111192bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=CountVectorizer()\n",
    "word_count_vector = cv.fit_transform(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b416ae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer(smooth_idf=True,use_idf=True) \n",
    "tfidf_transformer.fit(word_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3a8867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print idf values \n",
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names_out(),columns=[\"idf_weights\"]) \n",
    " \n",
    "# sort ascending \n",
    "df_idf = df_idf.sort_values(by=['idf_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99831974",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_idf.to_csv('idf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ea5943",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "important_words = list(df_idf[-10000:].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258359d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5b1e19",
   "metadata": {},
   "source": [
    "### Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60322818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca81124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp_groups = masnavi_df.groupby(['Daftar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c039816b",
   "metadata": {},
   "outputs": [],
   "source": [
    "poems = []\n",
    "for name, group in dp_groups:\n",
    "    poems.append([t for l in group['Couplet_tokenized'] for t in l if t in important_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3687e64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(poems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95ba172",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in masnavi_df.Couplet_tokenized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f9e02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model =  gensim.models.LdaMulticore(bow_corpus, \n",
    "                                   num_topics = 300, \n",
    "                                   id2word = dictionary,                                    \n",
    "                                   passes = 10,\n",
    "                                   workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbeed8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_path = datapath(\"model\")\n",
    "lda_model.save(lda_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def1b7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = lda_model.load(lda_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52214848",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3750789f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
